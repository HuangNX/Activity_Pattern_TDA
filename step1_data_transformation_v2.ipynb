{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 原始数据转序列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>date</th>\n",
       "      <th>t_start</th>\n",
       "      <th>t_end</th>\n",
       "      <th>poi_id</th>\n",
       "      <th>community_id</th>\n",
       "      <th>ptype</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>week</th>\n",
       "      <th>weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90221</td>\n",
       "      <td>2019-05-06</td>\n",
       "      <td>2019-05-06 07:28:00</td>\n",
       "      <td>2019-05-06 22:51:56</td>\n",
       "      <td>1</td>\n",
       "      <td>2291</td>\n",
       "      <td>2</td>\n",
       "      <td>114.185092</td>\n",
       "      <td>22.651382</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90221</td>\n",
       "      <td>2019-05-07</td>\n",
       "      <td>2019-05-07 00:52:01</td>\n",
       "      <td>2019-05-07 11:44:26</td>\n",
       "      <td>0</td>\n",
       "      <td>2291</td>\n",
       "      <td>1</td>\n",
       "      <td>114.174066</td>\n",
       "      <td>22.640383</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90221</td>\n",
       "      <td>2019-05-07</td>\n",
       "      <td>2019-05-07 12:09:41</td>\n",
       "      <td>2019-05-07 13:39:58</td>\n",
       "      <td>0</td>\n",
       "      <td>2291</td>\n",
       "      <td>1</td>\n",
       "      <td>114.174066</td>\n",
       "      <td>22.640383</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90221</td>\n",
       "      <td>2019-05-07</td>\n",
       "      <td>2019-05-07 13:41:28</td>\n",
       "      <td>2019-05-07 16:42:16</td>\n",
       "      <td>1</td>\n",
       "      <td>2291</td>\n",
       "      <td>2</td>\n",
       "      <td>114.185092</td>\n",
       "      <td>22.651382</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90221</td>\n",
       "      <td>2019-05-07</td>\n",
       "      <td>2019-05-07 16:43:47</td>\n",
       "      <td>2019-05-07 23:14:57</td>\n",
       "      <td>0</td>\n",
       "      <td>2291</td>\n",
       "      <td>1</td>\n",
       "      <td>114.174066</td>\n",
       "      <td>22.640383</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pid       date             t_start               t_end  poi_id  \\\n",
       "0  90221 2019-05-06 2019-05-06 07:28:00 2019-05-06 22:51:56       1   \n",
       "1  90221 2019-05-07 2019-05-07 00:52:01 2019-05-07 11:44:26       0   \n",
       "2  90221 2019-05-07 2019-05-07 12:09:41 2019-05-07 13:39:58       0   \n",
       "3  90221 2019-05-07 2019-05-07 13:41:28 2019-05-07 16:42:16       1   \n",
       "4  90221 2019-05-07 2019-05-07 16:43:47 2019-05-07 23:14:57       0   \n",
       "\n",
       "   community_id  ptype   longitude   latitude  week  weekday  \n",
       "0          2291      2  114.185092  22.651382    19        0  \n",
       "1          2291      1  114.174066  22.640383    19        1  \n",
       "2          2291      1  114.174066  22.640383    19        1  \n",
       "3          2291      2  114.185092  22.651382    19        1  \n",
       "4          2291      1  114.174066  22.640383    19        1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#读取数据\n",
    "filename = 'data/stay_one_community_2019.csv'\n",
    "act_points2019 = pd.read_csv(filename,parse_dates=['t_start', 't_end'])\n",
    "act_points2019['date'] = pd.to_datetime(act_points2019['date'],format='%Y-%m-%d')\n",
    "act_points2019.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3ptype\n",
    "#原始ptype：0-到访，1-居住，2-工作，3-出行，\n",
    "#现在，令0-居住（基点），1-出行，2-工作，3-到访（即其他活动）\n",
    "dict_ = {0:3, 1:0, 2:2}\n",
    "act_points2019['ptype'] = act_points2019['ptype'].map(dict_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 选取5~8月数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成月份标签\n",
    "act_points2019['month'] = [data.month for data in act_points2019['date']]\n",
    "\n",
    "# 月份选取\n",
    "act_points2019_58 = act_points2019.query('month in [5,6,7,8]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_points2019_58.to_csv('data/act_201958.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 实施转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#以周为单位构建长时间序列（周一到周日为一周）,采取将天序列拼接后再reshape的方法\n",
    "#序列长度24*60*7=10080\n",
    "def act_2_sequence_in_week(act):\n",
    "    from datetime import datetime\n",
    "    Sequence_in_week = []\n",
    "    \n",
    "    for weekday in range(7):\n",
    "        \n",
    "        act_day = act.query(f'weekday=={weekday}')\n",
    "        sequence = np.zeros(1440)\n",
    "        for index in range(len(act_day)):\n",
    "            \n",
    "            data = act_day.iloc[index,:]\n",
    "\n",
    "            #考虑隔日的活动，如从23:00到次日1:00 → t_start，t_end与date比较，并进行截断，t_start->0:00，t_end->23:59\n",
    "            if data['t_start'].day != data['date'].day:\n",
    "                data['t_start'] = datetime(data['date'].year,data['date'].month,data['date'].day,0,0,0)\n",
    "            elif data['t_end'].day != data['date'].day:\n",
    "                data['t_end'] = datetime(data['date'].year,data['date'].month,data['date'].day,23,59,59)\n",
    "\n",
    "            #根据时间段修改初始活动类型\n",
    "            act_begin = data['t_start'].hour*60 + data['t_start'].minute\n",
    "            act_end = data['t_end'].hour*60 + data['t_end'].minute\n",
    "            sequence[act_begin:act_end] = [data['ptype'] for i in range(act_end - act_begin)]\n",
    "\n",
    "            #根据相邻活动的时间段加入出行，对出行时长小于15min且出行连接的活动类型一样的要去掉\n",
    "            if index < len(act_day)-1:\n",
    "                #下一个活动的数据\n",
    "                data1 = act_day.iloc[index+1,:]\n",
    "                #定义出行时间\n",
    "                trip_begin = data['t_end'].hour*60 + data['t_end'].minute\n",
    "                trip_end = data1['t_start'].hour*60+data1['t_start'].minute\n",
    "\n",
    "                if (trip_end - trip_begin < 15) & (data['ptype'] == data1['ptype']):\n",
    "                    sequence[trip_begin:trip_end] = [data['ptype'] for i in range(trip_end - trip_begin)]\n",
    "                else:\n",
    "                    sequence[trip_begin:trip_end] = [1 for i in range(trip_end - trip_begin)]\n",
    "        \n",
    "        Sequence_in_week.append(sequence)\n",
    "    \n",
    "    Sequence_in_week = np.array(Sequence_in_week).reshape(10080)\n",
    "    \n",
    "    return Sequence_in_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>week</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90221</td>\n",
       "      <td>19</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90221</td>\n",
       "      <td>20</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90221</td>\n",
       "      <td>21</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90221</td>\n",
       "      <td>22</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90221</td>\n",
       "      <td>24</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pid  week                                                  0\n",
       "0  90221    19  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "1  90221    20  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "2  90221    21  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "3  90221    22  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "4  90221    24  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 对个体和周序号分组求序列\n",
    "trajectory_groups_in_week = act_points2019_58.groupby(['pid','week'],group_keys=False)\n",
    "trajectory_in_week1 = trajectory_groups_in_week.apply(act_2_sequence_in_week).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory_in_week1 = trajectory_in_week1.rename(columns = {0: \"week_trajectory\"})\n",
    "trajectory_in_week1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1335"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trajectory_in_week1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除整周在家的轨迹（自成一类，不需分析）\n",
    "trajectory_out = trajectory_in_week1\n",
    "for index,data in enumerate(trajectory_out['week_trajectory']):\n",
    "    #print(data)\n",
    "    if (~data.any()):\n",
    "        trajectory_out = trajectory_out.drop(index = index)\n",
    "\n",
    "trajectory_in_week1 = trajectory_out.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory[['pid','week']].to_csv('pid_week_201958.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 沃什-傅立叶变换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wft, copy from chen et.al.\n",
    "def wft(x,num):\n",
    "    Ipower = np.zeros(15) #时间序列长度不大于2^15\n",
    "    y = np.zeros(num)\n",
    "    \n",
    "    \n",
    "    for i in range(num):\n",
    "        IB = i\n",
    "        IL=0\n",
    "        \n",
    "        while True:\n",
    "            IBD = int(IB/2)\n",
    "            Ipower[IL] = 0 if IB == (IBD * 2) else 1\n",
    "                \n",
    "            if IB == 0 or IBD == 0:\n",
    "                break\n",
    "            IB = IBD\n",
    "            IL = IL + 1\n",
    "        \n",
    "        IP = 0\n",
    "        IFAC = num\n",
    "        for t1 in range(IL+1):\n",
    "            IFAC = int (IFAC / 2)\n",
    "            IP = int (IP + IFAC * Ipower[t1])\n",
    "        \n",
    "        y[IP] = x[i]\n",
    "        \n",
    "    \n",
    "    x = y.copy()\n",
    "    Iter = int(np.log2(num))\n",
    "    for M in range(Iter):\n",
    "        nump = 1 if M==0 else int(nump*2)\n",
    "        Mnum = int (num / nump)\n",
    "        Mnum2 = int(Mnum / 2)\n",
    "        alph = 1\n",
    "        for MP in range(nump):\n",
    "            IB = int(MP * Mnum)\n",
    "            \n",
    "            for MP2 in range(Mnum2):\n",
    "                mnum21 = int(Mnum2 + MP2 + IB) \n",
    "                IBA = int(IB + MP2)\n",
    "                y[IBA] = x[IBA] + alph * x[mnum21]\n",
    "                y[mnum21] = x[IBA] - alph * x[mnum21]\n",
    "\n",
    "            alph = -alph\n",
    "        \n",
    "        r = np.power(num,-0.5)\n",
    "        for i in range(num):\n",
    "            x[i] = y[i] * r\n",
    "        \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory = trajectory_in_week1['week_trajectory']\n",
    "dim = len(trajectory)\n",
    "next2 = np.power(2,int(np.log2(dim)+1))\n",
    "WFTs = []\n",
    "\n",
    "# sequence = np.pad(trajectory[0],(0,next2-dim),'constant', constant_values=(0, 0))\n",
    "# wft_seq = wft(sequence,next2)\n",
    "\n",
    "for index,data in enumerate(trajectory):\n",
    "    # 0 padding\n",
    "    sequence = np.pad(data,(0,next2-dim),'constant', constant_values=(0, 0))\n",
    "    wft_seq = wft(sequence,next2)\n",
    "    WFTs.append(wft_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 储存一下wft的结果（运行太久了，，，）\n",
    "np.savetxt(\"data/wft_week_3ptype_2019_58.txt\", WFTs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基于子水平集的持续同调"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from teaspoon.TDA.SLSP import Persistence0D\n",
    "from gtda.diagrams import Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WFTs = np.loadtxt('data/wft_week_3ptype_2019_58.txt')\n",
    "len(WFTs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用sublevel set function对WFT作持续同调，提取0维birth-death点\n",
    "PH_0dim = []\n",
    "\n",
    "for index,data in enumerate(WFTs):\n",
    "    feature_ind_1, feature_ind_2, persistenceDgm = Persistence0D(data) \n",
    "    #indices of birth times, indices of death times, points set\n",
    "    X = np.zeros((len(persistenceDgm),3))\n",
    "    if bool(len(persistenceDgm)):\n",
    "        X[:,0:2] = persistenceDgm #有空数组就会报错\n",
    "    X_3dim = X[np.newaxis,:,:]\n",
    "    scaler = Scaler()\n",
    "    persistenceDgm = scaler.fit_transform(X_3dim)\n",
    "    PH_0dim.append(persistenceDgm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#可视化\n",
    "dt = PH_0dim[0].reshape((PH_0dim[0].shape[1],3))\n",
    "plt.plot(dt[:,0],dt[:,1],'ro')\n",
    "#plt.plot([min(WFTs[0])*1e+24, max(WFTs[0])*1e+24], [min(WFTs[0])*1e+24, max(WFTs[0])*1e+24],'k--')\n",
    "plt.plot([-2,2], [-2,2],'k--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 持续同调图中的特征提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from gtda.diagrams import PersistenceEntropy\n",
    "from gtda.images import HeightFiltration\n",
    "from gtda.diagrams import Amplitude\n",
    "\n",
    "#Listing all metrics we want to use to extract diagram amplitudes\n",
    "metric_list = [\n",
    "    {\"metric\": \"bottleneck\", \"metric_params\": {}},\n",
    "    {\"metric\": \"wasserstein\", \"metric_params\": {\"p\": 1}},\n",
    "    {\"metric\": \"wasserstein\", \"metric_params\": {\"p\": 2}},\n",
    "    {\"metric\": \"landscape\", \"metric_params\": {\"p\": 1, \"n_layers\": 1, \"n_bins\": 100}},\n",
    "    {\"metric\": \"landscape\", \"metric_params\": {\"p\": 1, \"n_layers\": 2, \"n_bins\": 100}},\n",
    "    {\"metric\": \"landscape\", \"metric_params\": {\"p\": 2, \"n_layers\": 1, \"n_bins\": 100}},\n",
    "    {\"metric\": \"landscape\", \"metric_params\": {\"p\": 2, \"n_layers\": 2, \"n_bins\": 100}},\n",
    "    {\"metric\": \"betti\", \"metric_params\": {\"p\": 1, \"n_bins\": 100}},\n",
    "    {\"metric\": \"betti\", \"metric_params\": {\"p\": 2, \"n_bins\": 100}},\n",
    "    {\"metric\": \"heat\", \"metric_params\": {\"p\": 1, \"sigma\": 1.6, \"n_bins\": 100}},\n",
    "    {\"metric\": \"heat\", \"metric_params\": {\"p\": 1, \"sigma\": 3.2, \"n_bins\": 100}},\n",
    "    {\"metric\": \"heat\", \"metric_params\": {\"p\": 2, \"sigma\": 1.6, \"n_bins\": 100}},\n",
    "    {\"metric\": \"heat\", \"metric_params\": {\"p\": 2, \"sigma\": 3.2, \"n_bins\": 100}},\n",
    "]\n",
    "\n",
    "#\n",
    "feature_union = make_union(\n",
    "    *[PersistenceEntropy(nan_fill_value=-1)]\n",
    "    + [Amplitude(**metric, n_jobs=-1) for metric in metric_list]\n",
    ")\n",
    "\n",
    "# tda_union = make_union(\n",
    "#     *[make_pipeline(*diagram_step, feature_union) for diagram_step in diagram_steps],\n",
    "#     n_jobs=-1\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Features = []\n",
    "for index,data in enumerate(PH_0dim):\n",
    "    feature = feature_union.fit_transform(data)\n",
    "    Features.append(feature)\n",
    "    print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Features_reshape = np.array(Features).reshape(np.array(Features).shape[0],np.array(Features).shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存特征！！！\n",
    "np.savetxt(\"data/persistence_features_week_2019_58.txt\", Features_reshape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
